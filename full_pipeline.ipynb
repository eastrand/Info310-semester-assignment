{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b674ee10",
   "metadata": {},
   "source": [
    "# Full Pipeline (Original Logic Preserved + Multithreaded Download)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2c9a8",
   "metadata": {},
   "source": [
    "## PDF Finder (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446844a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_finder.py\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from typing import List, Set\n",
    "\n",
    "def find_pdf_links(url: str, base_url: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Navigates a specified URL, handles cookie banner, clicks 'See all results',\n",
    "    and scrapes all unique PDF links on the resulting page.\n",
    "\n",
    "    Args:\n",
    "        url: The starting URL for the search.\n",
    "        base_url: The base URL to prepend to relative links.\n",
    "\n",
    "    Returns:\n",
    "        A set of absolute PDF URLs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    \n",
    "    # Making the window fullscreen\n",
    "    driver.maximize_window()\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        # --- Handle Cookie Banner ---\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\")) \n",
    "        )\n",
    "        driver.find_element(By.TAG_NAME, \"body\").click() \n",
    "        actions = ActionChains(driver)\n",
    "        actions.send_keys(Keys.TAB).send_keys(Keys.ENTER).perform()\n",
    "        print(\"Accepted cookies using keyboard actions (Tab + Enter).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not interact with the cookie banner (maybe it didn't appear). Error: {e}\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    # --- Click 'See all results' ---\n",
    "    see_all_results_selector = \"a.btn.btn-primary.fit-content\"\n",
    "    try:\n",
    "        button_element = WebDriverWait(driver, 20).until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, see_all_results_selector))\n",
    "        )\n",
    "        \n",
    "        # Scroll to and click the button\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button_element)\n",
    "        time.sleep(0.5) \n",
    "        driver.execute_script(\"arguments[0].click();\", button_element)\n",
    "\n",
    "        print(\"Clicked the 'See all results' link/button using JavaScript force-click.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not interact with the 'See all results' button. Error: {e}\")\n",
    "        driver.quit() # Ensure the driver closes if this fails\n",
    "        return set() # Return an empty set\n",
    "\n",
    "    # Giving the webpage time to load completely\n",
    "    # NOTE: 35 seconds is quite long; ensure this time is necessary!\n",
    "    time.sleep(35) \n",
    "\n",
    "    # --- Find the PDF URLs ---\n",
    "    # Finding the pdf urls\n",
    "    # Filtering out the agreements that are not in English\n",
    "    # **NOTE: Ensure this CSS selector is correct for the final page!**\n",
    "    link_elements = driver.find_elements(By.CSS_SELECTOR, \"a[href$='.pdf']:not(.btn-download)\")\n",
    "\n",
    "    pdf_urls_set = set()\n",
    "    for link_element in link_elements:\n",
    "        href = link_element.get_attribute('href')\n",
    "        if href:\n",
    "            if not href.startswith(\"http\"):\n",
    "                absolute_url = base_url + href\n",
    "                pdf_urls_set.add(absolute_url)\n",
    "            else:\n",
    "                pdf_urls_set.add(href)\n",
    "\n",
    "    print(f\"Found {len(pdf_urls_set)} unique PDF URLs.\")\n",
    "\n",
    "    # Always close the browser when finished\n",
    "    driver.quit()\n",
    "    \n",
    "    # Return the collected URLs\n",
    "    return pdf_urls_set\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # This block allows you to test the function directly if you run the .py file\n",
    "    URL = \"https://www.peaceagreements.org/agreements/search/?search_type=basic-search&show_timeline=0&match_any_issues=True\"\n",
    "    BASE_URL = \"https://www.peaceagreements.org\"\n",
    "    \n",
    "    # Example usage when running the file directly\n",
    "    all_pdf_links = find_pdf_links(URL, BASE_URL)\n",
    "    \n",
    "    if all_pdf_links:\n",
    "        print(\"\\nFirst 5 URLs collected:\")\n",
    "        for link in list(all_pdf_links)[:5]:\n",
    "            print(link)\n",
    "    else:\n",
    "        print(\"\\nNo links were found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576b60d",
   "metadata": {},
   "source": [
    "## Multithreaded PDF Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a149e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import concurrent.futures, requests, os\n",
    "from pathlib import Path\n",
    "\n",
    "def download_pdf(url, outdir):\n",
    "    out=Path(outdir); out.mkdir(exist_ok=True)\n",
    "    fname=url.split('/')[-1].split('?')[0]\n",
    "    path=out/fname\n",
    "    if path.exists(): return path\n",
    "    try:\n",
    "        r=requests.get(url,timeout=20)\n",
    "        r.raise_for_status()\n",
    "        path.write_bytes(r.content)\n",
    "        return path\n",
    "    except Exception as e:\n",
    "        print(\"Fail\",url,e)\n",
    "        return None\n",
    "\n",
    "def download_all(urls, outdir=\"downloads\", max_workers=10):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        return list(ex.map(lambda u: download_pdf(u,outdir), urls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1dcc44",
   "metadata": {},
   "source": [
    "## chunk_docs.py (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def chunk_documents_parallel(\n",
    "    pdf_dir: str,\n",
    "    txt_dir: str,\n",
    "    chunk_size: int = 1500,\n",
    "    chunk_overlap: int = 200,\n",
    "    output_path=\"document_chunks.pkl\",\n",
    "    workers=8\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads and chunks PDF files from `pdf_dir` and TXT files from `txt_dir` in parallel.\n",
    "\n",
    "    Returns a pickle file containing:\n",
    "        [\n",
    "            {\n",
    "                \"doc_id\": filename,\n",
    "                \"document_text\": full_text,\n",
    "                \"chunks\": [Document, Document, ...]\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "\n",
    "    all_docs = []\n",
    "\n",
    "    # ----------------------------\n",
    "    #   Helper to process 1 file\n",
    "    # ----------------------------\n",
    "    def process_file(file_path: str, filename: str, is_pdf: bool):\n",
    "        try:\n",
    "            # Load text\n",
    "            if is_pdf:\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                pages = loader.load()\n",
    "                full_text = \"\\n\".join([p.page_content for p in pages])\n",
    "            else:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                    full_text = f.read()\n",
    "\n",
    "            doc_id = filename\n",
    "\n",
    "            # Chunk text\n",
    "            chunks = text_splitter.split_text(full_text)\n",
    "            chunk_docs = [\n",
    "                Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\n",
    "                        \"source\": file_path,\n",
    "                        \"chunk_id\": f\"{doc_id}-chunk:{i}\",\n",
    "                        \"doc_id\": doc_id,\n",
    "                    },\n",
    "                )\n",
    "                for i, chunk in enumerate(chunks)\n",
    "            ]\n",
    "\n",
    "            return {\n",
    "                \"doc_id\": doc_id,\n",
    "                \"document_text\": full_text,\n",
    "                \"chunks\": chunk_docs,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing {filename}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # ----------------------------\n",
    "    #      Collect file lists\n",
    "    # ----------------------------\n",
    "    pdf_files = [\n",
    "        (os.path.join(pdf_dir, f), f, True)\n",
    "        for f in os.listdir(pdf_dir)\n",
    "        if f.lower().endswith(\".pdf\")\n",
    "    ]\n",
    "\n",
    "    txt_files = [\n",
    "        (os.path.join(txt_dir, f), f, False)\n",
    "        for f in os.listdir(txt_dir)\n",
    "        if f.lower().endswith(\".txt\")\n",
    "    ]\n",
    "\n",
    "    # ----------------------------\n",
    "    #     Parallel processing\n",
    "    # ----------------------------\n",
    "    def run_parallel(file_list, desc):\n",
    "        results = []\n",
    "        with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "            futures = {\n",
    "                executor.submit(process_file, path, fname, is_pdf): fname\n",
    "                for path, fname, is_pdf in file_list\n",
    "            }\n",
    "\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=desc):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "\n",
    "        return results\n",
    "\n",
    "    print(\"ðŸ“„ Processing PDFs...\")\n",
    "    all_docs.extend(run_parallel(pdf_files, \"PDFs\"))\n",
    "\n",
    "    print(\"ðŸ“ Processing text files...\")\n",
    "    all_docs.extend(run_parallel(txt_files, \"TXTs\"))\n",
    "\n",
    "    # ----------------------------\n",
    "    #        Save results\n",
    "    # ----------------------------\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pickle.dump(all_docs, f)\n",
    "\n",
    "    print(f\"âœ… Saved {len(all_docs)} documents to {output_path}\")\n",
    "    return all_docs\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--pdf-dir\", required=True)\n",
    "    parser.add_argument(\"--txt-dir\", required=True)\n",
    "    parser.add_argument(\"--chunk-size\", type=int, default=1500)\n",
    "    parser.add_argument(\"--chunk-overlap\", type=int, default=200)\n",
    "    parser.add_argument(\"--output\", default=\"document_chunks.pkl\")\n",
    "    parser.add_argument(\"--workers\", type=int, default=8)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    chunk_documents_parallel(\n",
    "        args.pdf_dir,\n",
    "        args.txt_dir,\n",
    "        args.chunk_size,\n",
    "        args.chunk_overlap,\n",
    "        args.output,\n",
    "        args.workers\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8322a",
   "metadata": {},
   "source": [
    "## ingest_vectors.py (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55445b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_core.documents import Document\n",
    "import torch\n",
    "import gc\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def ingest_vectors(pkl_path, embeddings, args):\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "    \n",
    "    print(f\"Loaded {len(dataset)} documents for vector ingestion\")\n",
    "    \n",
    "    # Setup progress tracking\n",
    "    progress_file = Path(args.progress_file)\n",
    "    completed_docs = set()\n",
    "    \n",
    "    if progress_file.exists():\n",
    "        with open(progress_file, \"r\") as f:\n",
    "            progress_data = json.load(f)\n",
    "            completed_docs = set(progress_data.get(\"completed_docs\", []))\n",
    "        print(f\"Resuming: {len(completed_docs)} documents already processed\")\n",
    "    \n",
    "    # Filter out already completed documents\n",
    "    docs_to_process = [d for d in dataset if d[\"doc_id\"] not in completed_docs]\n",
    "    print(f\"Processing {len(docs_to_process)} remaining documents\")\n",
    "    \n",
    "    vector_store_config = {\n",
    "        \"embedding\": embeddings,\n",
    "        \"url\": args.neo4j_url,\n",
    "        \"username\": args.neo4j_user,\n",
    "        \"password\": args.neo4j_password,\n",
    "        \"index_name\": args.index_name,\n",
    "        \"node_label\": \"Chunk\",\n",
    "        \"text_node_property\": \"text\",\n",
    "        \"embedding_node_property\": \"embedding\"\n",
    "    }\n",
    "    \n",
    "    # Create vector store (index auto-created if needed)\n",
    "    vector_store = Neo4jVector(**vector_store_config)\n",
    "    \n",
    "    def process_doc(doc_entry):\n",
    "        doc_id = doc_entry[\"doc_id\"]\n",
    "        chunks = doc_entry[\"chunks\"]\n",
    "        \n",
    "        # Store main document node\n",
    "        query_doc = \"\"\"\n",
    "        MERGE (d:Document {doc_id: $doc_id})\n",
    "        SET d.source = $source, d.text = $text\n",
    "        \"\"\"\n",
    "        vector_store._driver.execute_query(\n",
    "            query_doc, \n",
    "            doc_id=doc_id, \n",
    "            source=chunks[0].metadata[\"source\"], \n",
    "            text=doc_entry[\"document_text\"]\n",
    "        )\n",
    "        \n",
    "        # Embed and store chunks\n",
    "        vector_store.add_documents(\n",
    "            chunks, \n",
    "            ids=[c.metadata[\"chunk_id\"] for c in chunks]\n",
    "        )\n",
    "        \n",
    "        # Link document to chunks\n",
    "        link_query = \"\"\"\n",
    "        MATCH (d:Document {doc_id: $doc_id})\n",
    "        UNWIND $chunk_ids AS cid\n",
    "        MATCH (c:Chunk {id: cid})\n",
    "        MERGE (d)-[:HAS_CHUNK]->(c)\n",
    "        \"\"\"\n",
    "        vector_store._driver.execute_query(\n",
    "            link_query, \n",
    "            doc_id=doc_id, \n",
    "            chunk_ids=[c.metadata[\"chunk_id\"] for c in chunks]\n",
    "        )\n",
    "        \n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return doc_id\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=args.concurrency) as executor:\n",
    "        futures = {executor.submit(process_doc, d): d for d in docs_to_process}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing docs\"):\n",
    "            try:\n",
    "                doc_id = future.result()\n",
    "                completed_docs.add(doc_id)\n",
    "                \n",
    "                # Save progress periodically\n",
    "                with open(progress_file, \"w\") as f:\n",
    "                    json.dump({\"completed_docs\": list(completed_docs)}, f)\n",
    "            except Exception as e:\n",
    "                doc_entry = futures[future]\n",
    "                print(f\"âš ï¸ Error processing {doc_entry['doc_id']}: {e}\")\n",
    "    \n",
    "    print(\"âœ… Vector ingestion complete\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--pkl\", default=\"document_chunks.pkl\")\n",
    "    parser.add_argument(\"--neo4j-url\", default=os.getenv(\"NEO4J_URL\"))\n",
    "    parser.add_argument(\"--neo4j-user\", default=os.getenv(\"NEO4J_USER\"))\n",
    "    parser.add_argument(\"--neo4j-password\", default=os.getenv(\"NEO4J_PASSWORD\"))\n",
    "    parser.add_argument(\"--index-name\", default=\"peace_index\")\n",
    "    parser.add_argument(\"--concurrency\", type=int, default=8)\n",
    "    parser.add_argument(\"--progress-file\", default=\"vector_ingestion_progress.json\")\n",
    "    parser.add_argument(\"--embedding-model\", default=os.getenv(\"EMBEDDING_MODEL\", \"text-embedding-3-small\"))\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=args.embedding_model,\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\", \"not-needed\"),\n",
    "        openai_api_base=os.getenv(\"OPENAI_API_BASE\")\n",
    "    )\n",
    "    \n",
    "    ingest_vectors(args.pkl, embeddings, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6173b2",
   "metadata": {},
   "source": [
    "## QA_retrieval.py (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc680e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# LLM RAW RESPONSE LOGGING DB\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "conn = sqlite3.connect(\"qa_logs.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS llm_raw_responses (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    timestamp TEXT,\n",
    "    question TEXT,\n",
    "    prompt TEXT,\n",
    "    raw_response TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Retrieval / context knobs\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "TOP_K_VECTOR = 25          # how many vector hits to pull\n",
    "TOP_K_KEYWORD = 25         # how many fulltext hits to pull (when fusion is on)\n",
    "TOP_K_KG = 15              # how many KG hits to pull (when fusion is on)\n",
    "TOP_K_FUSED = 20           # how many fused results to keep for context\n",
    "\n",
    "MAX_CONTEXT_CHARS = 24000  # hard cap on context size passed to GPT\n",
    "MAX_CHARS_PER_CHUNK = 2000 # truncate very long chunks for safety\n",
    "\n",
    "# ============================================================\n",
    "# SQLite logging for final QA answers\n",
    "# ============================================================\n",
    "\n",
    "QA_DB_PATH = \"qa_answers.db\"\n",
    "\n",
    "\n",
    "def init_qa_db():\n",
    "    conn = sqlite3.connect(QA_DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS answers (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            timestamp TEXT,\n",
    "            question TEXT,\n",
    "            answer TEXT,\n",
    "            fusion_enabled INTEGER\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def log_qa_answer(question: str, answer: str, fusion_enabled: bool):\n",
    "    conn = sqlite3.connect(QA_DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO answers (timestamp, question, answer, fusion_enabled)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", (\n",
    "        datetime.utcnow().isoformat(),\n",
    "        question,\n",
    "        answer,\n",
    "        1 if fusion_enabled else 0\n",
    "    ))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Neo4j helper\n",
    "# ============================================================\n",
    "\n",
    "def neo4j_query(driver, query: str, params: dict) -> List[Dict]:\n",
    "    with driver.session() as session:\n",
    "        return session.run(query, params).data()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Retrieval helpers (vector, fulltext, KG)\n",
    "# ============================================================\n",
    "\n",
    "def get_vector_results(question: str, driver, client: OpenAI) -> List[Dict]:\n",
    "    \"\"\"Retrieve top chunks by vector similarity.\"\"\"\n",
    "    embedding = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",  # must match ingest\n",
    "        input=question\n",
    "    ).data[0].embedding\n",
    "\n",
    "    query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes('chunk_embeddings', $topK, $embedding)\n",
    "    YIELD node, score\n",
    "    RETURN node.doc_id AS doc_id, node.text AS text, score\n",
    "    ORDER BY score DESC\n",
    "    \"\"\"\n",
    "\n",
    "    return neo4j_query(driver, query, {\n",
    "        \"embedding\": embedding,\n",
    "        \"topK\": TOP_K_VECTOR,\n",
    "    })\n",
    "\n",
    "\n",
    "def get_fulltext_results(question: str, driver) -> List[Dict]:\n",
    "    \"\"\"Retrieve top chunks using fulltext index on :Chunk(text).\"\"\"\n",
    "    query = f\"\"\"\n",
    "    CALL db.index.fulltext.queryNodes('chunk_fulltext', $q)\n",
    "    YIELD node, score\n",
    "    RETURN node.doc_id AS doc_id, node.text AS text, score\n",
    "    ORDER BY score DESC\n",
    "    LIMIT {TOP_K_KEYWORD}\n",
    "    \"\"\"\n",
    "    return neo4j_query(driver, query, {\"q\": question})\n",
    "\n",
    "\n",
    "def get_kg_results(question: str, driver) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Simple KG-based retrieval:\n",
    "    find Documents linked from entities whose name contains the query string.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    MATCH (e)-[:DERIVED_FROM]->(d:Document)\n",
    "    WHERE e.name CONTAINS $q\n",
    "    RETURN d.doc_id AS doc_id, d.text AS text, 1.0 AS score\n",
    "    LIMIT {TOP_K_KG}\n",
    "    \"\"\"\n",
    "    return neo4j_query(driver, query, {\"q\": question})\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RAG fusion scoring (chunk-level)\n",
    "# ============================================================\n",
    "\n",
    "def reciprocal_rank_fusion(result_lists: List[List[Dict]], k: int = TOP_K_FUSED) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Reciprocal Rank Fusion over chunk-level results.\n",
    "    Each result is a dict with at least: doc_id, text, score.\n",
    "    We dedupe by (doc_id, text) so multiple chunks from the same doc\n",
    "    can still appear, but identical duplicates won't.\n",
    "    \"\"\"\n",
    "    def _index_map(results: List[Dict]):\n",
    "        return {(r[\"doc_id\"], r[\"text\"]): idx for idx, r in enumerate(results)}\n",
    "\n",
    "    # Build index maps\n",
    "    maps = [_index_map(results) for results in result_lists]\n",
    "\n",
    "    # All unique (doc_id, text) keys\n",
    "    all_keys = set()\n",
    "    for m in maps:\n",
    "        all_keys |= set(m.keys())\n",
    "\n",
    "    scores = {}\n",
    "    for key in all_keys:\n",
    "        rr = 0.0\n",
    "        for m in maps:\n",
    "            if key in m:\n",
    "                # standard RRF scoring\n",
    "                rr += 1.0 / (60 + m[key])\n",
    "        scores[key] = rr\n",
    "\n",
    "    # Sort by fused score\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Turn back into list of result dicts\n",
    "    fused_results = []\n",
    "    # Flatten all results for lookup\n",
    "    flat = []\n",
    "    for lst in result_lists:\n",
    "        flat.extend(lst)\n",
    "\n",
    "    for (doc_id, text), score in ranked[:k]:\n",
    "        # find one matching entry to copy fields from\n",
    "        match = next((r for r in flat if r[\"doc_id\"] == doc_id and r[\"text\"] == text), None)\n",
    "        if match:\n",
    "            fused_results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"text\": text,\n",
    "                \"score\": score\n",
    "            })\n",
    "\n",
    "    return fused_results\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Context building\n",
    "# ============================================================\n",
    "\n",
    "def build_context(results: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Build a structured context string from retrieval results, with:\n",
    "    - doc headers\n",
    "    - chunk truncation\n",
    "    - global char budget\n",
    "    \"\"\"\n",
    "    pieces = []\n",
    "    total_chars = 0\n",
    "\n",
    "    for r in results:\n",
    "        doc_id = r.get(\"doc_id\", \"unknown_doc\")\n",
    "        text = r.get(\"text\", \"\") or \"\"\n",
    "\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # Truncate overly long chunks for safety\n",
    "        if len(text) > MAX_CHARS_PER_CHUNK:\n",
    "            text = text[:MAX_CHARS_PER_CHUNK] + \" ... [truncated]\"\n",
    "\n",
    "        section = f\"[DOC: {doc_id}]\\n{text}\"\n",
    "\n",
    "        # Enforce global context budget\n",
    "        if total_chars + len(section) + 5 > MAX_CONTEXT_CHARS:\n",
    "            break\n",
    "\n",
    "        pieces.append(section)\n",
    "        total_chars += len(section) + 5  # +5 for separators\n",
    "\n",
    "    return \"\\n\\n-----\\n\\n\".join(pieces)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Answer synthesis using LLM\n",
    "# ============================================================\n",
    "\n",
    "def generate_answer(context: str, question: str, client: OpenAI):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert analyst answering questions about peace agreements, security arrangements, and related political texts.\n",
    "\n",
    "You MUST:\n",
    "- Use ONLY the information in the context below (no outside knowledge).\n",
    "- Be as EXHAUSTIVE as possible given the context.\n",
    "- Synthesize across multiple documents and chunks when needed.\n",
    "- If the context gives only a partial answer, say clearly: \"This answer is based only on the retrieved documents and may be incomplete.\"\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "Answer in clear, structured bullet points (or short paragraphs if more natural).\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_completion_tokens=10000,\n",
    "        # temperature=0,  # gpt-5 doesn't support custom temperature yet\n",
    "    )\n",
    "\n",
    "    raw_json = json.dumps(response.model_dump(), indent=2)\n",
    "\n",
    "    # Store in SQLite (raw LLM response)\n",
    "    conn = sqlite3.connect(\"qa_logs.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"\n",
    "        INSERT INTO llm_raw_responses (timestamp, question, prompt, raw_response)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", (\n",
    "        datetime.utcnow().isoformat(),\n",
    "        question,\n",
    "        prompt,\n",
    "        raw_json\n",
    "    ))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main QA function\n",
    "# ============================================================\n",
    "\n",
    "def answer_question(question: str, use_fusion: bool = False):\n",
    "    # Connect to Neo4j\n",
    "    driver = GraphDatabase.driver(\n",
    "        os.getenv(\"NEO4J_URI\"),\n",
    "        auth=(os.getenv(\"NEO4J_USER\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    "    )\n",
    "\n",
    "    # OpenAI client\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1. Retrieval\n",
    "    # ------------------------------------------------------------\n",
    "    vec_results = get_vector_results(question, driver, client)\n",
    "    kw_results = get_fulltext_results(question, driver)\n",
    "    kg_results = get_kg_results(question, driver)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2. Fusion or vanilla RAG\n",
    "    # ------------------------------------------------------------\n",
    "    if use_fusion:\n",
    "        fused = reciprocal_rank_fusion([vec_results, kw_results, kg_results])\n",
    "        retrieval_used = fused\n",
    "    else:\n",
    "        # Just vector search; keep top-K_FUSED\n",
    "        retrieval_used = vec_results[:TOP_K_FUSED]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3. Build context string\n",
    "    # ------------------------------------------------------------\n",
    "    context = build_context(retrieval_used)\n",
    "\n",
    "    # (Optional debug)\n",
    "    # print(\"\\n---- VECTOR RESULTS ----\")\n",
    "    # print(vec_results)\n",
    "    # print(\"\\n---- FULLTEXT RESULTS ----\")\n",
    "    # print(kw_results)\n",
    "    # print(\"\\n---- KG RESULTS ----\")\n",
    "    # print(kg_results)\n",
    "    # print(\"\\n---- CONTEXT SENT TO MODEL (truncated) ----\")\n",
    "    # print(context[:2000])\n",
    "    # print(\"... (truncated) ...\")\n",
    "\n",
    "    # If somehow nothing was retrieved\n",
    "    if not context.strip():\n",
    "        answer = (\n",
    "            \"I could not retrieve any relevant context from the database for this question, \"\n",
    "            \"so I cannot provide a grounded answer.\"\n",
    "        )\n",
    "        return answer\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4. Generate LLM answer\n",
    "    # ------------------------------------------------------------\n",
    "    answer = generate_answer(context, question, client)\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CLI ENTRYPOINT â€” with SQLite logging\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    import sys\n",
    "\n",
    "    init_qa_db()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--q\", help=\"Single question\")\n",
    "    parser.add_argument(\"--questions-file\", help=\"File containing one question per line\")\n",
    "    parser.add_argument(\"--fusion\", action=\"store_true\", help=\"Enable RAG Fusion scoring\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    questions = []\n",
    "\n",
    "    if args.q:\n",
    "        questions.append(args.q)\n",
    "\n",
    "    if args.questions_file and os.path.exists(args.questions_file):\n",
    "        with open(args.questions_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            questions.extend([line.strip() for line in f.readlines() if line.strip()])\n",
    "\n",
    "    if not questions:\n",
    "        print(\"No questions provided. Nothing to do.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    for q in questions:\n",
    "        print(\"\\n====================================================\")\n",
    "        print(f\"QUESTION: {q}\")\n",
    "        print(\"====================================================\\n\")\n",
    "\n",
    "        ans = answer_question(q, use_fusion=args.fusion)\n",
    "\n",
    "        print(\"ANSWER:\\n\")\n",
    "        print(ans)\n",
    "        print(\"\\n----------------------------------------------------\\n\")\n",
    "\n",
    "        # Log into DB\n",
    "        log_qa_answer(q, ans, args.fusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924edc6",
   "metadata": {},
   "source": [
    "## QA_retrieval_eval.py (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "from openai import OpenAI\n",
    "\n",
    "# DeepEval imports\n",
    "from deepeval.metrics import (\n",
    "    ContextualPrecisionMetric,\n",
    "    # ContextualRecallMetric,\n",
    "    ContextualRelevancyMetric,\n",
    "    AnswerRelevancyMetric,\n",
    "    FaithfulnessMetric,\n",
    ")\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval import evaluate\n",
    "\n",
    "# Import your existing QA pipeline\n",
    "import QA_retrieval\n",
    "from QA_retrieval import neo4j_query, reciprocal_rank_fusion\n",
    "\n",
    "# If these constants exist in QA_retrieval, reuse them; else set safe defaults\n",
    "MAX_CONTEXT_CHARS = getattr(QA_retrieval, \"MAX_CONTEXT_CHARS\", 24000)\n",
    "MAX_CHARS_PER_CHUNK = getattr(QA_retrieval, \"MAX_CHARS_PER_CHUNK\", 2000)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def sanitize_lucene(q: str) -> str:\n",
    "    bad = r'+ - && || ! ( ) { } [ ] ^ \" ~ * ? : \\ /'\n",
    "    for c in bad.split():\n",
    "        q = q.replace(c, \" \")\n",
    "    return q\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Context reconstruction that mirrors QA_retrieval logic\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def get_context_for_question(\n",
    "    question: str,\n",
    "    use_fusion: bool,\n",
    "    driver,\n",
    "    client: OpenAI,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Rebuilds the RAG context chunks using the same retrieval logic\n",
    "    as QA_retrieval.answer_question.\n",
    "\n",
    "    Returns a list of chunk strings (one per retrieved text).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Embed question â€“ same model as in QA_retrieval\n",
    "    embedding = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=question\n",
    "    ).data[0].embedding\n",
    "\n",
    "    # 2) Vector search (same Cypher as your QA script)\n",
    "    vec_query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes('chunk_embeddings', 5, $embedding)\n",
    "    YIELD node, score\n",
    "    RETURN node.doc_id AS doc_id, node.text AS text, score\n",
    "    \"\"\"\n",
    "\n",
    "    vec_results = neo4j_query(driver, vec_query, {\"embedding\": embedding})\n",
    "\n",
    "    # 3) Fulltext search (same as QA)\n",
    "    kw_query = \"\"\"\n",
    "    CALL db.index.fulltext.queryNodes('chunk_fulltext', $q)\n",
    "    YIELD node, score\n",
    "    RETURN node.doc_id AS doc_id, node.text AS text, score\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "\n",
    "    kw_results = neo4j_query(driver, kw_query, {\"q\": sanitize_lucene(question)})\n",
    "\n",
    "    # 4) KG search (same as QA)\n",
    "    kg_query = \"\"\"\n",
    "    MATCH (e)-[:DERIVED_FROM]->(d:Document)\n",
    "    WHERE e.name CONTAINS $q\n",
    "    RETURN d.doc_id AS doc_id, d.text AS text, 1 AS score\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "\n",
    "    kg_results = neo4j_query(driver, kg_query, {\"q\": question})\n",
    "\n",
    "    # 5) Fusion vs vanilla\n",
    "    if use_fusion:\n",
    "        fused = reciprocal_rank_fusion([vec_results, kw_results, kg_results])\n",
    "\n",
    "        # If reciprocal_rank_fusion already returns full result dicts (as your debug shows)\n",
    "        if fused and isinstance(fused[0], dict):\n",
    "            ranked_results = fused\n",
    "            print(\"Fused:\", fused)\n",
    "        else:\n",
    "            # Fallback: fused is a list of doc_id's â€“ map them back to rows\n",
    "            all_results = vec_results + kw_results + kg_results\n",
    "            result_map = {str(r[\"doc_id\"]): r for r in all_results}\n",
    "            ranked_results = []\n",
    "            for d in fused:\n",
    "                r = result_map.get(str(d))\n",
    "                if r:\n",
    "                    ranked_results.append(r)\n",
    "\n",
    "        top_contexts = []\n",
    "        for r in ranked_results[:4]:\n",
    "            text = r.get(\"text\") or \"\"\n",
    "            if len(text) > MAX_CHARS_PER_CHUNK:\n",
    "                text = text[:MAX_CHARS_PER_CHUNK]\n",
    "            top_contexts.append(text)\n",
    "\n",
    "    else:\n",
    "        top_contexts = []\n",
    "        for r in vec_results[:4]:\n",
    "            text = r.get(\"text\") or \"\"\n",
    "            if len(text) > MAX_CHARS_PER_CHUNK:\n",
    "                text = text[:MAX_CHARS_PER_CHUNK]\n",
    "            top_contexts.append(text)\n",
    "    print(\"VEC:\", len(vec_results))\n",
    "    print(\"KW:\", len(kw_results))\n",
    "    print(\"KG:\", len(kg_results))\n",
    "    print(\"Matched contexts:\", len(top_contexts))\n",
    "    # Hard cap total context length\n",
    "    joined = \"\\n\\n\".join(top_contexts)\n",
    "    if len(joined) > MAX_CONTEXT_CHARS:\n",
    "        joined = joined[:MAX_CONTEXT_CHARS]\n",
    "\n",
    "    # If no contexts, return an empty list instead of ['']\n",
    "    if not joined:\n",
    "        return []\n",
    "\n",
    "    return joined.split(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load eval dataset\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def load_eval_set(path: str):\n",
    "    \"\"\"\n",
    "    CSV with columns: question, ground_truth\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            q = row.get(\"question\", \"\").strip()\n",
    "            gt = row.get(\"ground_truth\", \"\").strip()\n",
    "            if q and gt:\n",
    "                rows.append({\"question\": q, \"ground_truth\": gt})\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DeepEval metrics\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def build_metrics():\n",
    "    contextual_precision = ContextualPrecisionMetric()\n",
    "    # contextual_recall = ContextualRecallMetric()\n",
    "    contextual_relevancy = ContextualRelevancyMetric()\n",
    "    answer_relevancy = AnswerRelevancyMetric()\n",
    "    faithfulness = FaithfulnessMetric()\n",
    "\n",
    "    return [\n",
    "        contextual_precision,\n",
    "        # contextual_recall,\n",
    "        contextual_relevancy,\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "    ]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main eval runner\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    import argparse\n",
    "    import traceback\n",
    "    import csv\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--eval-file\",\n",
    "        default=\"rag_eval_set.csv\",\n",
    "        help=\"CSV with columns: question,ground_truth\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fusion\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Use the same RAG fusion mode as QA_retrieval (vector+fulltext+KG).\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    eval_rows = load_eval_set(args.eval_file)\n",
    "    if not eval_rows:\n",
    "        print(f\"No rows found in {args.eval_file}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Setup\n",
    "    driver = GraphDatabase.driver(\n",
    "        os.getenv(\"NEO4J_URI\"),\n",
    "        auth=(os.getenv(\"NEO4J_USER\"), os.getenv(\"NEO4J_PASSWORD\")),\n",
    "    )\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    metrics = build_metrics()\n",
    "\n",
    "    # Prepare raw output logging\n",
    "    raw_output_path = \"eval_raw_outputs.csv\"\n",
    "    with open(raw_output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"question\", \"ground_truth\", \"model_answer\", \"error\"])\n",
    "\n",
    "    print(f\"Running evaluation on {len(eval_rows)} questions.\")\n",
    "    print(f\"Fusion mode: {'ON' if args.fusion else 'OFF'}\\n\")\n",
    "\n",
    "    # Evaluate each question *individually*\n",
    "    for i, row in enumerate(eval_rows, start=1):\n",
    "        q = row[\"question\"]\n",
    "        gt = row[\"ground_truth\"]\n",
    "\n",
    "        print(f\"\\n============================\")\n",
    "        print(f\"[{i}/{len(eval_rows)}] QUESTION\")\n",
    "        print(q)\n",
    "\n",
    "        answer = None\n",
    "        error_msg = None\n",
    "        ctx_chunks = []\n",
    "\n",
    "        # ---- Step 1 â€” safe answer generation ----\n",
    "        try:\n",
    "            answer = QA_retrieval.answer_question(q, use_fusion=args.fusion)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Answer error: {repr(e)}\"\n",
    "            print(\"\\nâŒ ERROR producing answer:\")\n",
    "            print(error_msg)\n",
    "            answer = \"ERROR\"\n",
    "\n",
    "        # ---- Step 2 â€” safe context retrieval ----\n",
    "        try:\n",
    "            if answer != \"ERROR\":\n",
    "                ctx_chunks = get_context_for_question(\n",
    "                    q, use_fusion=args.fusion, driver=driver, client=client\n",
    "                )\n",
    "        except Exception as e:\n",
    "            err = f\"Context error: {repr(e)}\"\n",
    "            print(\"\\nâš ï¸ ERROR retrieving context (skipping context):\")\n",
    "            print(err)\n",
    "            error_msg = error_msg or err\n",
    "            ctx_chunks = []\n",
    "\n",
    "        # ---- Save raw output immediately ----\n",
    "        with open(raw_output_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([q, gt, answer, error_msg or \"\"])\n",
    "\n",
    "        # ---- Step 3 â€” run metrics *for this single question* ----\n",
    "        # ---- Step 3 â€” run metrics *for this single question* ----\n",
    "        try:\n",
    "            tc = LLMTestCase(\n",
    "                input=q,\n",
    "                actual_output=answer,\n",
    "                expected_output=gt,\n",
    "                retrieval_context=ctx_chunks,\n",
    "            )\n",
    "\n",
    "            per_q_results = evaluate(\n",
    "                test_cases=[tc],\n",
    "                metrics=metrics,\n",
    "            )\n",
    "\n",
    "            print(\"\\nðŸ“Š METRICS:\")\n",
    "\n",
    "            # DeepEval returns an object, not a dict\n",
    "            for metric_result in per_q_results.metrics_data:\n",
    "                name = metric_result.metric_name\n",
    "                score = metric_result.score\n",
    "\n",
    "                # score is already a float\n",
    "                print(f\"- {name}: {score:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"\\nâŒ ERROR running DeepEval metrics:\")\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "\n",
    "\n",
    "    print(\"\\n============================\")\n",
    "    print(\"Evaluation complete.\")\n",
    "    print(f\"Raw outputs saved to: {raw_output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037c068",
   "metadata": {},
   "source": [
    "## extract_kg.py (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import os\n",
    "import yaml\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_PATH = \"kg_raw_responses.db\"\n",
    "\n",
    "\n",
    "def init_db():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "    # Create table if it doesn't exist\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS responses (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            timestamp TEXT,\n",
    "            doc_id TEXT,\n",
    "            status TEXT,          -- 'success', 'empty', 'parse_error', 'api_error'\n",
    "            raw_response TEXT,    -- full JSON response from the API\n",
    "            content TEXT,         -- message.content\n",
    "            parsed_json TEXT,     -- parsed JSON (entities/relationships)\n",
    "            error TEXT            -- error message / finish_reason notes\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "    # Ensure raw_response column exists even if table was created earlier without it\n",
    "    cur.execute(\"PRAGMA table_info(responses)\")\n",
    "    cols = [row[1] for row in cur.fetchall()]\n",
    "    if \"raw_response\" not in cols:\n",
    "        cur.execute(\"ALTER TABLE responses ADD COLUMN raw_response TEXT\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def log_response(\n",
    "    doc_id: str,\n",
    "    status: str,\n",
    "    raw_response: str = \"\",\n",
    "    content: str = \"\",\n",
    "    parsed_json: str = \"\",\n",
    "    error: str = \"\",\n",
    "):\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO responses (timestamp, doc_id, status, raw_response, content, parsed_json, error)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\",\n",
    "        (\n",
    "            datetime.utcnow().isoformat(),\n",
    "            doc_id,\n",
    "            status,\n",
    "            raw_response,\n",
    "            content,\n",
    "            parsed_json,\n",
    "            error,\n",
    "        ),\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def load_schema(schema_path: str) -> dict:\n",
    "    \"\"\"Load and parse the schema YAML file.\"\"\"\n",
    "    with open(schema_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "def build_schema_prompt(schema: dict) -> str:\n",
    "    \"\"\"Build a prompt section describing the schema.\"\"\"\n",
    "    prompt_parts = []\n",
    "\n",
    "    if \"entities\" in schema:\n",
    "        entity_lines = []\n",
    "        for entity_dict in schema[\"entities\"]:\n",
    "            for entity_type, description in entity_dict.items():\n",
    "                entity_lines.append(f\"- {entity_type}: {description}\")\n",
    "        prompt_parts.append(\"Extract these entity types:\\n\" + \"\\n\".join(entity_lines))\n",
    "\n",
    "    if \"relationships\" in schema:\n",
    "        rel_lines = []\n",
    "        for rel_dict in schema[\"relationships\"]:\n",
    "            for rel_type, rel_spec in rel_dict.items():\n",
    "                rel_lines.append(f\"- {rel_type}: {rel_spec}\")\n",
    "        prompt_parts.append(\n",
    "            \"\\nExtract these relationship types:\\n\" + \"\\n\".join(rel_lines)\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(prompt_parts)\n",
    "\n",
    "\n",
    "def serialize_response(response) -> str:\n",
    "    \"\"\"\n",
    "    Best-effort conversion of the OpenAI response object into a JSON string.\n",
    "    Handles different client versions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        obj = response.model_dump()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            obj = response.to_dict()\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                # Some clients have .json() returning a string\n",
    "                text = response.json()\n",
    "                # If that's already JSON, keep it as-is\n",
    "                json.loads(text)\n",
    "                return text\n",
    "            except Exception:\n",
    "                obj = str(response)\n",
    "    if isinstance(obj, str):\n",
    "        return obj\n",
    "    return json.dumps(obj, ensure_ascii=False)\n",
    "\n",
    "\n",
    "async def extract_kg(args):\n",
    "    \"\"\"Extract a knowledge graph from stored document nodes in Neo4j.\"\"\"\n",
    "    client = AsyncOpenAI(\n",
    "        base_url=args.llm_base_url,\n",
    "        api_key=args.llm_api_key,\n",
    "    )\n",
    "    driver = GraphDatabase.driver(\n",
    "        args.neo4j_url,\n",
    "        auth=(args.neo4j_user, args.neo4j_password),\n",
    "    )\n",
    "\n",
    "    # Load schema\n",
    "    schema = load_schema(args.schema_path)\n",
    "    schema_prompt = build_schema_prompt(schema)\n",
    "\n",
    "    # Progress tracking\n",
    "    progress_file = Path(args.progress_file)\n",
    "    completed_docs = set()\n",
    "    if progress_file.exists():\n",
    "        with open(progress_file, \"r\") as f:\n",
    "            progress_data = json.load(f)\n",
    "            completed_docs = set(progress_data.get(\"completed_docs\", []))\n",
    "        print(f\"Resuming: {len(completed_docs)} documents already processed\")\n",
    "\n",
    "    # Load documents from Neo4j\n",
    "    with driver.session() as session:\n",
    "        docs = session.run(\n",
    "            \"MATCH (d:Document) RETURN d.doc_id AS id, d.text AS text\"\n",
    "        ).data()\n",
    "\n",
    "    docs_to_process = [d for d in docs if d[\"id\"] not in completed_docs]\n",
    "    print(f\"Extracting KG from {len(docs_to_process)} remaining documents\")\n",
    "\n",
    "    semaphore = asyncio.Semaphore(args.concurrent_requests)\n",
    "\n",
    "    async def process_doc(doc):\n",
    "        \"\"\"Process a single document with the LLM and write results to Neo4j.\"\"\"\n",
    "        doc_id = doc[\"id\"]\n",
    "        text = doc[\"text\"] or \"\"\n",
    "\n",
    "        system_prompt = (\n",
    "            \"You are an information extraction model. \"\n",
    "            \"Return only valid JSON with two arrays: 'entities' and 'relationships'. \"\n",
    "            \"Do not include any explanations or reasoning text.\"\n",
    "        )\n",
    "        user_prompt = f\"\"\"Extract entities and relationships from this document according to the following schema:\n",
    "\n",
    "{schema_prompt}\n",
    "\n",
    "Return JSON in this exact format:\n",
    "{{\"entities\":[{{\"type\":\"\",\"name\":\"\",\"properties\":{{}}}}], \"relationships\":[{{\"source\":\"\",\"target\":\"\",\"type\":\"\",\"properties\":{{}}}}]}}\n",
    "\n",
    "Document text:\n",
    "{text[:10000]}\"\"\"  # truncate if too long\n",
    "\n",
    "        try:\n",
    "            response = await client.chat.completions.create(\n",
    "                model=args.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                max_completion_tokens=20048,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                # extra_body={\"service_tier\": \"flex\"},\n",
    "\n",
    "            )\n",
    "\n",
    "            raw_response_str = serialize_response(response)\n",
    "            choice = response.choices[0]\n",
    "            msg = choice.message\n",
    "            raw_content = msg.content or \"\"\n",
    "            finish_reason = choice.finish_reason\n",
    "\n",
    "            # If model didn't actually return any visible content,\n",
    "            # log and bail out for this doc.\n",
    "            if not raw_content.strip():\n",
    "                log_response(\n",
    "                    doc_id,\n",
    "                    status=\"empty\",\n",
    "                    raw_response=raw_response_str,\n",
    "                    content=raw_content,\n",
    "                    parsed_json=\"\",\n",
    "                    error=f\"finish_reason={finish_reason}, no content returned\",\n",
    "                )\n",
    "                return\n",
    "\n",
    "            # Try to parse JSON\n",
    "            try:\n",
    "                parsed = json.loads(raw_content)\n",
    "            except Exception as e:\n",
    "                log_response(\n",
    "                    doc_id,\n",
    "                    status=\"parse_error\",\n",
    "                    raw_response=raw_response_str,\n",
    "                    content=raw_content,\n",
    "                    parsed_json=\"\",\n",
    "                    error=f\"{type(e).__name__}: {e}\",\n",
    "                )\n",
    "                return\n",
    "\n",
    "            # Log successful parse\n",
    "            log_response(\n",
    "                doc_id,\n",
    "                status=\"success\",\n",
    "                raw_response=raw_response_str,\n",
    "                content=raw_content,\n",
    "                parsed_json=json.dumps(parsed, ensure_ascii=False),\n",
    "                error=f\"finish_reason={finish_reason}\",\n",
    "            )\n",
    "\n",
    "            entities = parsed.get(\"entities\") or []\n",
    "            relationships = parsed.get(\"relationships\") or []\n",
    "\n",
    "            with driver.session() as session:\n",
    "                # Insert entities\n",
    "                for ent in entities:\n",
    "                    if not isinstance(ent, dict):\n",
    "                        continue\n",
    "\n",
    "                    name = ent.get(\"name\")\n",
    "                    if not name:\n",
    "                        continue\n",
    "\n",
    "                    entity_type = ent.get(\"type\", \"Entity\")\n",
    "                    properties = ent.get(\"properties\", {}) or {}\n",
    "                    properties[\"name\"] = name\n",
    "\n",
    "                    prop_items = \", \".join([f\"e.{k} = ${k}\" for k in properties.keys()])\n",
    "\n",
    "                    session.run(\n",
    "                        f\"MERGE (e:{entity_type} {{name: $name}}) \"\n",
    "                        f\"SET {prop_items} \"\n",
    "                        \"WITH e MATCH (d:Document {doc_id: $doc_id}) \"\n",
    "                        \"MERGE (e)-[:DERIVED_FROM]->(d)\",\n",
    "                        **properties,\n",
    "                        doc_id=doc_id,\n",
    "                    )\n",
    "\n",
    "                # Insert relationships\n",
    "                for rel in relationships:\n",
    "                    if not isinstance(rel, dict):\n",
    "                        continue\n",
    "\n",
    "                    src = rel.get(\"source\")\n",
    "                    tgt = rel.get(\"target\")\n",
    "                    if not src or not tgt:\n",
    "                        continue\n",
    "\n",
    "                    rel_type = rel.get(\"type\", \"RELATED_TO\").upper().replace(\" \", \"_\")\n",
    "                    properties = rel.get(\"properties\", {}) or {}\n",
    "\n",
    "                    if properties:\n",
    "                        prop_items = \", \".join(\n",
    "                            [f\"r.{k} = ${k}\" for k in properties.keys()]\n",
    "                        )\n",
    "                        prop_set = f\"SET {prop_items}\"\n",
    "                    else:\n",
    "                        prop_set = \"\"\n",
    "\n",
    "                    session.run(\n",
    "                        f\"MATCH (s {{name: $src}}), (t {{name: $tgt}}) \"\n",
    "                        f\"MERGE (s)-[r:{rel_type}]->(t) \"\n",
    "                        f\"{prop_set}\",\n",
    "                        src=src,\n",
    "                        tgt=tgt,\n",
    "                        **properties,\n",
    "                    )\n",
    "\n",
    "            # Mark doc as completed\n",
    "            completed_docs.add(doc_id)\n",
    "            with open(progress_file, \"w\") as f:\n",
    "                json.dump({\"completed_docs\": list(completed_docs)}, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch API / connection errors\n",
    "            log_response(\n",
    "                doc_id,\n",
    "                status=\"api_error\",\n",
    "                raw_response=\"\",\n",
    "                content=\"\",\n",
    "                parsed_json=\"\",\n",
    "                error=f\"{type(e).__name__}: {e}\",\n",
    "            )\n",
    "            print(f\"âš ï¸ Error processing {doc_id}: {e}\")\n",
    "\n",
    "    async def process_with_semaphore(doc):\n",
    "        async with semaphore:\n",
    "            await process_doc(doc)\n",
    "\n",
    "    tasks = [process_with_semaphore(d) for d in docs_to_process]\n",
    "    for coro in tqdm(\n",
    "        asyncio.as_completed(tasks), total=len(tasks), desc=\"KG extraction\"\n",
    "    ):\n",
    "        await coro\n",
    "\n",
    "    driver.close()\n",
    "    print(\"âœ… KG extraction complete\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    init_db()\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--neo4j-url\", default=os.getenv(\"NEO4J_URI\"))\n",
    "    parser.add_argument(\"--neo4j-user\", default=os.getenv(\"NEO4J_USER\"))\n",
    "    parser.add_argument(\"--neo4j-password\", default=os.getenv(\"NEO4J_PASSWORD\"))\n",
    "    parser.add_argument(\n",
    "        \"--llm-base-url\",\n",
    "        default=os.getenv(\"LLM_BASE_URL\", \"https://api.openai.com/v1\"),\n",
    "    )\n",
    "    parser.add_argument(\"--llm-api-key\", default=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    parser.add_argument(\"--model\", default=os.getenv(\"LLM_MODEL\", \"gpt-5-mini\"))\n",
    "    parser.add_argument(\"--schema-path\", default=\"schema.yaml\")\n",
    "    parser.add_argument(\"--progress-file\", default=\"kg_extraction_progress.json\")\n",
    "    parser.add_argument(\"--concurrent-requests\", type=int, default=5)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    asyncio.run(extract_kg(args))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
